{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "1.1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y1NSPraXm4Q9",
        "outputId": "2b0a7df5-81f9-4771-fad5-e32631a8d6fd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2.1\n",
        "\n",
        "\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G4wIVr62xKQq",
        "outputId": "2e00521f-f1ef-47e2-ef73-4fe78e168de0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2.2\n",
        "\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Path to the model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/Indic_GPT2/gpt2_ai4b020_e1_model\"\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "k-0J3nHWxO7u"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.1\n",
        "\n",
        "# BAD PROMPT\n",
        "\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"तुम्हारा उद्देश्य क्या है?\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text 1\n",
        "#outputs = model.generate(\n",
        " #   input_ids,\n",
        "  #  max_length=100,  # Maximum length of the generated text\n",
        "  #  num_return_sequences=1,  # Number of generated outputs\n",
        "  #  no_repeat_ngram_size=2,  # Avoid repetition of phrases\n",
        "  #  temperature=0.7,  # Controls creativity; lower is more deterministic\n",
        "  #  top_k=50,  # Filters top k tokens for sampling\n",
        "  #  top_p=0.95,  # Nucleus sampling\n",
        "  #  do_sample=True,  # Enables sampling\n",
        "\n",
        "\n",
        "\n",
        "#)\n",
        "\n",
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=200,  # Increased max length\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,  # Adjust as needed\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.2,\n",
        "    num_beams=5  # Optional: Use beam search\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXkROVzexUuc",
        "outputId": "048b3e18-2794-484b-b110-6409572411e8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "कैसे पढ़ाई करते हैं । क्या आप जानते हैं कि कैसे पढ़ाई करते हैं और कैसे पढ़ाई करते हैं । क्या आप जानते हैं कैं क्या क्या क्या क्या क्या\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3.1\n",
        "\n",
        "# GOOD PROMPT\n",
        "\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"ऐ दिल है मुश्किल\"\n",
        "\n",
        "# हेलो - दोस्तों आज हम आपको बताने जा रहे हैं कि कैसे आप अपने बच्चे को\n",
        "# कुछ बोलो - मैं तो कुछ बोलो । मैं तो कुछ बोलो । मैं तो कुछ बोलो । �\n",
        "# भारत के बारे में बताओ - कि क्या है वह किसी भी समय की बात की जाए तो क्या ह�\n",
        "# कुछ बताओ - कि कुछ समय पहले ही केंद्र सरकार ने कहा था कि कोरोना वायरस क\n",
        "# आप कौन हो - या नहीं इसके लिए आपको क्या करना चाहिए ? आप कौन होगा या नह\n",
        "# NASA के बारे में बताओ - कि ये सब कुछ है जिसके बारे में हम सभी जानते हैं । य\n",
        "\n",
        "#### e1_p1_Model\n",
        "\n",
        "# नमस्ते, आप कैसे हैं? ------------- मैं आपको बताऊंगा कि आप कैसे किस तरह के कैस�\n",
        "# मेरा दिन काफी व्यस्त था। आपका दिन कैसा रहा? ------------- आप सब को बता दें कि मैं आप\n",
        "# आज मौसम कैसा है? ------------- क्या है आपके पास क्या है ? आज के समय में कई लोग ऐसे ह\n",
        "# मुझे एक आसान भारतीय नाश्ते की रेसिपी बताइए। ------------- मैं आपको बताऊंगा कि आ\n",
        "# एक रोचक कहानी  ------------- है कि मैं अपने पिता के साथ किसी भी प्रकार की कहानी को �\n",
        "# उत्तर भारतीय और दक्षिण भारतीय  ------------- दोनों ही देशों में सबसे अधिक स\n",
        "# विदेश यात्रा ------------- विदेश यात्रा के लिए सबसे बड़ी समस्या यह है कि वि�\n",
        "# आपका नाम क्या है? ------------- आप क्या करते हैं ? आप क्या करते हैं ? आप क्या करते है�\n",
        "# आपका नाम ------------- सुनते ही हमारे दिमाग में कई तरह के स्वाद आते हैं । लेकिन क\n",
        "# अपने बारे में कुछ बताओ ------------- कि क्या आप जानते हैं कि क्या आपको पता है कि कै\n",
        "# कहानी क्या है  ------------- इसके अलावा कहानी के सम्बन्ध में कहानी के अनुसार क�\n",
        "# आज आपका मूड कैसा है? ------------- आप के लिए क्या करें ? आप के लिए क्या करें ? आप के ल�\n",
        "# देशों में सबसे ------------- बड़ी कंपनी मारुति सुजुकी की कार कंपनी है । इस कं�\n",
        "# Hello ------------- ! Forgot your password ? A password will be e - mailed to you . पेट्रोल , डीजल की कीमतों में बढोत्तरी परेशान क्�\n",
        "# tell me a story ------------- of the day . मुझे यह बताने की जरूरत नहीं है कि मैं अपने पिता के साथ कुछ न�\n",
        "# tell me a joke ------------- of the Indian Expressway , the Indian Expressway ,\n",
        "# who are you? ------------- क्या आप जानते हैं कि क्या आपको किसी भी प्रकार की समस्या होती ह\n",
        "# do you speak hindi? ------------- क्या आप जानते हैं कि क्या आपको किसी भी प्रकार की समस्या होती\n",
        "# आप क्या जानते हैं? ------------- क्या है ? आप क्या जानते हैं ?\n",
        "# तनहा दिल तनहा सफर ------------- ढूंढे तुम्हे  । तुम क्या करोगे ? तुम्हारे पास क्\n",
        "# कभी कभी मेरे दिल में  ------------- । मैं तो कभी कभी मेरे दिल में । मैं तो कभी �\n",
        "# ऐ दिल है मुश्किल  ------------- । मुश्किल है मुश्किल । मुश्किल है मुश्किल ।\n",
        "# मैं आपको बताऊंगा कि ------------- आप अपने बच्चे को कैसे पढ़ाई करते हैं और क्या आ\n",
        "# हसीना जान ऐ मन ------------- । मैं तुम्हारे पास क्या हूँ ? मैं तुम्हारे पास क्या ह\n",
        "#\n",
        "\n",
        "#### e1_p2_Model\n",
        "\n",
        "# दुःख ------------- की स्थिति में कोई संदेह नहीं है कि क्या वह संसार के सभी प्रा�\n",
        "# सुख ------------- सुखदेव की प्रतिमा को समर्पित है । सुखदेव की प्रतिमा को समर्पि�\n",
        "\n",
        "# नमस्ते, आप कैसे हैं? -------------\n",
        "\n",
        "# आज मौसम कैसा है? -------------  क्या है ? क्या है आपकी सेहत का ध्यान ? आज के समय में आ\n",
        "# विदेश यात्रा ------------- विदेश यात्रा के दौरान विदेश यात्रा के दौरान विदे�\n",
        "# एक रोचक कहानी -------------  कहानी के अनुसार किसी भी प्रकार की कहानी को समझने क\n",
        "# उत्तर भारतीय और दक्षिण भारतीय ------------- संस्कृति के अनुसार हर साल की तरह इ\n",
        "\n",
        "# Hello ------------- मुंबई । बॉलीवुड के मशहूर अभिनेता सलमान खान की फिल्म ' किसी का भ\n",
        "# tell me a story ------------- of the Indian Man . मैं तुम्हारी बहुत बड़ी बात कह रहा हूँ । मैं तुम्हारी बहुत\n",
        "# tell me a joke ------------- किसी को भी किसी को भी किसी को भी किसी को भी किसी को भी किसी को भ�\n",
        "# who are you? ------------- क्या आप जानते हैं कि कैसे आपके पास क्या है ? क्या आपको पता है कि आ\n",
        "# do you speak hindi? ------------- किसी को भी किसी को भी किसी को भी किसी को भी किसी को भी किसी क�\n",
        "# तनहा दिल तनहा सफर ------------- सफर करने के लिए क्या करता है ? तनहा दिल तनहा सफर करने �\n",
        "# ऐ दिल है मुश्किल ------------- में मुझे क्या करना चाहिए ? मुश्किल में मुश्किल\n",
        "# कभी कभी मेरे दिल में  ------------- कुछ ऐसा होता है कि मैं किसी को भी किसी को भी कि\n",
        "# देशों में सबसे ------------- ज्यादा प्रतिष्ठित संस्थानों में से एक के रूप मे�\n",
        "# आपका नाम ------------- सुनते ही आपके मन में कुछ ऐसा होता होगा जो आपके साथ किसी को भ\n",
        "#\n",
        "\n",
        "# Tokenize the input prompt\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text\n",
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=100,  # Limit the output length\n",
        "    num_return_sequences=1,  # Number of sequences to generate\n",
        "    temperature=0.7,  # Control randomness (lower is less random)\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pgiQ2o3nX8M",
        "outputId": "e9fa820f-ae17-4638-bbd7-7f027aef8925"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "ऐ दिल है मुश्किल में मुझे क्या करना चाहिए ? \n",
            " मुश्किल में मुश्किल\n"
          ]
        }
      ]
    }
  ]
}